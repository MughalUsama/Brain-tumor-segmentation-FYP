{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Copy of Copy of FYP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MughalUsama/Brain-tumor-segmentation-FYP/blob/d3/resnet50training_FYP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owTxwa0aBTyG"
      },
      "source": [
        "Mounting  Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acL_eT6O5XPA",
        "outputId": "0acc2579-7b7d-4833-a346-bc1fc72e7db4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDWrNEfZBRrq"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import h5py\n",
        "import cv2\n",
        "#from PIL import Image"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ1IIA-mPOFE"
      },
      "source": [
        "Xtrain = np.ndarray(shape = (900,512,512)) #1564 + 500 + 1000\n",
        "Ytrain = np.zeros(900)\n",
        "\n",
        "# Xval = np.ndarray(shape = (500,512,512)) #1564 + 500 + 1000\n",
        "# Yval = np.zeros(500)\n",
        "\n",
        "# Xtest = np.ndarray(shape = (1000,512,512)) #1564 + 500 + 1000\n",
        "# Ytest = np.zeros(1000)\n",
        "\n",
        "train_count = 0\n",
        "test_count= 0\n",
        "val_count = 0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdDW3JhZDUAc",
        "outputId": "d2e54cc5-ca03-425f-c420-0ebd219f1dcd"
      },
      "source": [
        "i = 1\n",
        "while i <3065:   \n",
        "    if train_count < 900:\n",
        "        if i < 767:\n",
        "          path = '/content/drive/MyDrive/TUMOR DATASET/tumor1.zip (Unzipped Files)/'\n",
        "        elif i < 1533:\n",
        "          path = '/content/drive/MyDrive/TUMOR DATASET/tumor3.zip (Unzipped Files)/'\n",
        "        elif i < 2299:\n",
        "          path = '/content/drive/MyDrive/TUMOR DATASET/tumor2.zip (Unzipped Files)/'\n",
        "        else:\n",
        "          path = '/content/drive/MyDrive/TUMOR DATASET/tumor4.zip (Unzipped Files)/'\n",
        "\n",
        "        f = h5py.File(path+str(i)+'.mat','r')\n",
        "        gr = f.get('cjdata')\n",
        "        im = np.array(gr.get('image'))\n",
        "        norm_image = cv2.normalize(im, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F) #for normalizing the images of dataset\n",
        "        norm_image = cv2.resize(norm_image, (512,512), interpolation = cv2.INTER_AREA)\n",
        "        Xtrain[train_count] = np.array(norm_image)\n",
        "        Ytrain[train_count] = gr.get('label')[()]\n",
        "        train_count +=1\n",
        "        i+=3\n",
        "        print(i)\n",
        "    else:\n",
        "      break\n",
        "    # if test_count < 1000:\n",
        "    #     if i < 767:\n",
        "    #       path = '/content/drive/MyDrive/TUMOR DATASET/tumor1.zip (Unzipped Files)/'\n",
        "    #     elif i < 1533:\n",
        "    #       path = '/content/drive/MyDrive/TUMOR DATASET/tumor3.zip (Unzipped Files)/'\n",
        "    #     elif i < 2299:\n",
        "    #       path = '/content/drive/MyDrive/TUMOR DATASET/tumor2.zip (Unzipped Files)/'\n",
        "    #     else:\n",
        "    #       path = '/content/drive/MyDrive/TUMOR DATASET/tumor4.zip (Unzipped Files)/'\n",
        "\n",
        "    #     # f = h5py.File(path+str(i)+'.mat','r')\n",
        "    #     # gr = f.get('cjdata')\n",
        "    #     # im = np.array(gr.get('image'))\n",
        "    #     # norm_image = cv2.normalize(im, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F) #for normalizing the images of dataset\n",
        "    #     # norm_image = cv2.resize(norm_image, (512,512), interpolation = cv2.INTER_AREA)\n",
        "\n",
        "    #     # Xtest[test_count] = np.array(norm_image)\n",
        "    #     # Ytest[test_count] = gr.get('label')[()]\n",
        "    #     test_count +=1\n",
        "    #     i+=1\n",
        "\n",
        "    # if val_count < 500:\n",
        "    #     if i < 767:\n",
        "    #       path = '/content/drive/MyDrive/TUMOR DATASET/tumor1.zip (Unzipped Files)/'\n",
        "    #     elif i < 1533:\n",
        "    #       path = '/content/drive/MyDrive/TUMOR DATASET/tumor3.zip (Unzipped Files)/'\n",
        "    #     elif i < 2299:\n",
        "    #       path = '/content/drive/MyDrive/TUMOR DATASET/tumor2.zip (Unzipped Files)/'\n",
        "    #     else:\n",
        "    #       path = '/content/drive/MyDrive/TUMOR DATASET/tumor4.zip (Unzipped Files)/'\n",
        "\n",
        "    #     f = h5py.File(path+str(i)+'.mat','r')\n",
        "    #     gr = f.get('cjdata')\n",
        "    #     im = np.array(gr.get('image'))\n",
        "    #     norm_image = cv2.normalize(im, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F) #for normalizing the images of dataset\n",
        "    #     norm_image = cv2.resize(norm_image, (512,512), interpolation = cv2.INTER_AREA)\n",
        "\n",
        "    #     Xval[val_count] = np.array(norm_image)\n",
        "    #     Yval[val_count] = gr.get('label')[()]\n",
        "    #     val_count +=1\n",
        "    #     i+=1\n",
        "\n",
        "    # print(i)\n",
        "\n",
        "#    print(np.max(norm_image))\n",
        "#    plt.imshow(norm_image, cmap=\"gray\") \n",
        "#  plt.show()\n",
        "#    print((gr.get('label')[()])) #cjdata.label: 1 for meningioma, 2 for glioma, 3 for pituitary tumor"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "7\n",
            "10\n",
            "13\n",
            "16\n",
            "19\n",
            "22\n",
            "25\n",
            "28\n",
            "31\n",
            "34\n",
            "37\n",
            "40\n",
            "43\n",
            "46\n",
            "49\n",
            "52\n",
            "55\n",
            "58\n",
            "61\n",
            "64\n",
            "67\n",
            "70\n",
            "73\n",
            "76\n",
            "79\n",
            "82\n",
            "85\n",
            "88\n",
            "91\n",
            "94\n",
            "97\n",
            "100\n",
            "103\n",
            "106\n",
            "109\n",
            "112\n",
            "115\n",
            "118\n",
            "121\n",
            "124\n",
            "127\n",
            "130\n",
            "133\n",
            "136\n",
            "139\n",
            "142\n",
            "145\n",
            "148\n",
            "151\n",
            "154\n",
            "157\n",
            "160\n",
            "163\n",
            "166\n",
            "169\n",
            "172\n",
            "175\n",
            "178\n",
            "181\n",
            "184\n",
            "187\n",
            "190\n",
            "193\n",
            "196\n",
            "199\n",
            "202\n",
            "205\n",
            "208\n",
            "211\n",
            "214\n",
            "217\n",
            "220\n",
            "223\n",
            "226\n",
            "229\n",
            "232\n",
            "235\n",
            "238\n",
            "241\n",
            "244\n",
            "247\n",
            "250\n",
            "253\n",
            "256\n",
            "259\n",
            "262\n",
            "265\n",
            "268\n",
            "271\n",
            "274\n",
            "277\n",
            "280\n",
            "283\n",
            "286\n",
            "289\n",
            "292\n",
            "295\n",
            "298\n",
            "301\n",
            "304\n",
            "307\n",
            "310\n",
            "313\n",
            "316\n",
            "319\n",
            "322\n",
            "325\n",
            "328\n",
            "331\n",
            "334\n",
            "337\n",
            "340\n",
            "343\n",
            "346\n",
            "349\n",
            "352\n",
            "355\n",
            "358\n",
            "361\n",
            "364\n",
            "367\n",
            "370\n",
            "373\n",
            "376\n",
            "379\n",
            "382\n",
            "385\n",
            "388\n",
            "391\n",
            "394\n",
            "397\n",
            "400\n",
            "403\n",
            "406\n",
            "409\n",
            "412\n",
            "415\n",
            "418\n",
            "421\n",
            "424\n",
            "427\n",
            "430\n",
            "433\n",
            "436\n",
            "439\n",
            "442\n",
            "445\n",
            "448\n",
            "451\n",
            "454\n",
            "457\n",
            "460\n",
            "463\n",
            "466\n",
            "469\n",
            "472\n",
            "475\n",
            "478\n",
            "481\n",
            "484\n",
            "487\n",
            "490\n",
            "493\n",
            "496\n",
            "499\n",
            "502\n",
            "505\n",
            "508\n",
            "511\n",
            "514\n",
            "517\n",
            "520\n",
            "523\n",
            "526\n",
            "529\n",
            "532\n",
            "535\n",
            "538\n",
            "541\n",
            "544\n",
            "547\n",
            "550\n",
            "553\n",
            "556\n",
            "559\n",
            "562\n",
            "565\n",
            "568\n",
            "571\n",
            "574\n",
            "577\n",
            "580\n",
            "583\n",
            "586\n",
            "589\n",
            "592\n",
            "595\n",
            "598\n",
            "601\n",
            "604\n",
            "607\n",
            "610\n",
            "613\n",
            "616\n",
            "619\n",
            "622\n",
            "625\n",
            "628\n",
            "631\n",
            "634\n",
            "637\n",
            "640\n",
            "643\n",
            "646\n",
            "649\n",
            "652\n",
            "655\n",
            "658\n",
            "661\n",
            "664\n",
            "667\n",
            "670\n",
            "673\n",
            "676\n",
            "679\n",
            "682\n",
            "685\n",
            "688\n",
            "691\n",
            "694\n",
            "697\n",
            "700\n",
            "703\n",
            "706\n",
            "709\n",
            "712\n",
            "715\n",
            "718\n",
            "721\n",
            "724\n",
            "727\n",
            "730\n",
            "733\n",
            "736\n",
            "739\n",
            "742\n",
            "745\n",
            "748\n",
            "751\n",
            "754\n",
            "757\n",
            "760\n",
            "763\n",
            "766\n",
            "769\n",
            "772\n",
            "775\n",
            "778\n",
            "781\n",
            "784\n",
            "787\n",
            "790\n",
            "793\n",
            "796\n",
            "799\n",
            "802\n",
            "805\n",
            "808\n",
            "811\n",
            "814\n",
            "817\n",
            "820\n",
            "823\n",
            "826\n",
            "829\n",
            "832\n",
            "835\n",
            "838\n",
            "841\n",
            "844\n",
            "847\n",
            "850\n",
            "853\n",
            "856\n",
            "859\n",
            "862\n",
            "865\n",
            "868\n",
            "871\n",
            "874\n",
            "877\n",
            "880\n",
            "883\n",
            "886\n",
            "889\n",
            "892\n",
            "895\n",
            "898\n",
            "901\n",
            "904\n",
            "907\n",
            "910\n",
            "913\n",
            "916\n",
            "919\n",
            "922\n",
            "925\n",
            "928\n",
            "931\n",
            "934\n",
            "937\n",
            "940\n",
            "943\n",
            "946\n",
            "949\n",
            "952\n",
            "955\n",
            "958\n",
            "961\n",
            "964\n",
            "967\n",
            "970\n",
            "973\n",
            "976\n",
            "979\n",
            "982\n",
            "985\n",
            "988\n",
            "991\n",
            "994\n",
            "997\n",
            "1000\n",
            "1003\n",
            "1006\n",
            "1009\n",
            "1012\n",
            "1015\n",
            "1018\n",
            "1021\n",
            "1024\n",
            "1027\n",
            "1030\n",
            "1033\n",
            "1036\n",
            "1039\n",
            "1042\n",
            "1045\n",
            "1048\n",
            "1051\n",
            "1054\n",
            "1057\n",
            "1060\n",
            "1063\n",
            "1066\n",
            "1069\n",
            "1072\n",
            "1075\n",
            "1078\n",
            "1081\n",
            "1084\n",
            "1087\n",
            "1090\n",
            "1093\n",
            "1096\n",
            "1099\n",
            "1102\n",
            "1105\n",
            "1108\n",
            "1111\n",
            "1114\n",
            "1117\n",
            "1120\n",
            "1123\n",
            "1126\n",
            "1129\n",
            "1132\n",
            "1135\n",
            "1138\n",
            "1141\n",
            "1144\n",
            "1147\n",
            "1150\n",
            "1153\n",
            "1156\n",
            "1159\n",
            "1162\n",
            "1165\n",
            "1168\n",
            "1171\n",
            "1174\n",
            "1177\n",
            "1180\n",
            "1183\n",
            "1186\n",
            "1189\n",
            "1192\n",
            "1195\n",
            "1198\n",
            "1201\n",
            "1204\n",
            "1207\n",
            "1210\n",
            "1213\n",
            "1216\n",
            "1219\n",
            "1222\n",
            "1225\n",
            "1228\n",
            "1231\n",
            "1234\n",
            "1237\n",
            "1240\n",
            "1243\n",
            "1246\n",
            "1249\n",
            "1252\n",
            "1255\n",
            "1258\n",
            "1261\n",
            "1264\n",
            "1267\n",
            "1270\n",
            "1273\n",
            "1276\n",
            "1279\n",
            "1282\n",
            "1285\n",
            "1288\n",
            "1291\n",
            "1294\n",
            "1297\n",
            "1300\n",
            "1303\n",
            "1306\n",
            "1309\n",
            "1312\n",
            "1315\n",
            "1318\n",
            "1321\n",
            "1324\n",
            "1327\n",
            "1330\n",
            "1333\n",
            "1336\n",
            "1339\n",
            "1342\n",
            "1345\n",
            "1348\n",
            "1351\n",
            "1354\n",
            "1357\n",
            "1360\n",
            "1363\n",
            "1366\n",
            "1369\n",
            "1372\n",
            "1375\n",
            "1378\n",
            "1381\n",
            "1384\n",
            "1387\n",
            "1390\n",
            "1393\n",
            "1396\n",
            "1399\n",
            "1402\n",
            "1405\n",
            "1408\n",
            "1411\n",
            "1414\n",
            "1417\n",
            "1420\n",
            "1423\n",
            "1426\n",
            "1429\n",
            "1432\n",
            "1435\n",
            "1438\n",
            "1441\n",
            "1444\n",
            "1447\n",
            "1450\n",
            "1453\n",
            "1456\n",
            "1459\n",
            "1462\n",
            "1465\n",
            "1468\n",
            "1471\n",
            "1474\n",
            "1477\n",
            "1480\n",
            "1483\n",
            "1486\n",
            "1489\n",
            "1492\n",
            "1495\n",
            "1498\n",
            "1501\n",
            "1504\n",
            "1507\n",
            "1510\n",
            "1513\n",
            "1516\n",
            "1519\n",
            "1522\n",
            "1525\n",
            "1528\n",
            "1531\n",
            "1534\n",
            "1537\n",
            "1540\n",
            "1543\n",
            "1546\n",
            "1549\n",
            "1552\n",
            "1555\n",
            "1558\n",
            "1561\n",
            "1564\n",
            "1567\n",
            "1570\n",
            "1573\n",
            "1576\n",
            "1579\n",
            "1582\n",
            "1585\n",
            "1588\n",
            "1591\n",
            "1594\n",
            "1597\n",
            "1600\n",
            "1603\n",
            "1606\n",
            "1609\n",
            "1612\n",
            "1615\n",
            "1618\n",
            "1621\n",
            "1624\n",
            "1627\n",
            "1630\n",
            "1633\n",
            "1636\n",
            "1639\n",
            "1642\n",
            "1645\n",
            "1648\n",
            "1651\n",
            "1654\n",
            "1657\n",
            "1660\n",
            "1663\n",
            "1666\n",
            "1669\n",
            "1672\n",
            "1675\n",
            "1678\n",
            "1681\n",
            "1684\n",
            "1687\n",
            "1690\n",
            "1693\n",
            "1696\n",
            "1699\n",
            "1702\n",
            "1705\n",
            "1708\n",
            "1711\n",
            "1714\n",
            "1717\n",
            "1720\n",
            "1723\n",
            "1726\n",
            "1729\n",
            "1732\n",
            "1735\n",
            "1738\n",
            "1741\n",
            "1744\n",
            "1747\n",
            "1750\n",
            "1753\n",
            "1756\n",
            "1759\n",
            "1762\n",
            "1765\n",
            "1768\n",
            "1771\n",
            "1774\n",
            "1777\n",
            "1780\n",
            "1783\n",
            "1786\n",
            "1789\n",
            "1792\n",
            "1795\n",
            "1798\n",
            "1801\n",
            "1804\n",
            "1807\n",
            "1810\n",
            "1813\n",
            "1816\n",
            "1819\n",
            "1822\n",
            "1825\n",
            "1828\n",
            "1831\n",
            "1834\n",
            "1837\n",
            "1840\n",
            "1843\n",
            "1846\n",
            "1849\n",
            "1852\n",
            "1855\n",
            "1858\n",
            "1861\n",
            "1864\n",
            "1867\n",
            "1870\n",
            "1873\n",
            "1876\n",
            "1879\n",
            "1882\n",
            "1885\n",
            "1888\n",
            "1891\n",
            "1894\n",
            "1897\n",
            "1900\n",
            "1903\n",
            "1906\n",
            "1909\n",
            "1912\n",
            "1915\n",
            "1918\n",
            "1921\n",
            "1924\n",
            "1927\n",
            "1930\n",
            "1933\n",
            "1936\n",
            "1939\n",
            "1942\n",
            "1945\n",
            "1948\n",
            "1951\n",
            "1954\n",
            "1957\n",
            "1960\n",
            "1963\n",
            "1966\n",
            "1969\n",
            "1972\n",
            "1975\n",
            "1978\n",
            "1981\n",
            "1984\n",
            "1987\n",
            "1990\n",
            "1993\n",
            "1996\n",
            "1999\n",
            "2002\n",
            "2005\n",
            "2008\n",
            "2011\n",
            "2014\n",
            "2017\n",
            "2020\n",
            "2023\n",
            "2026\n",
            "2029\n",
            "2032\n",
            "2035\n",
            "2038\n",
            "2041\n",
            "2044\n",
            "2047\n",
            "2050\n",
            "2053\n",
            "2056\n",
            "2059\n",
            "2062\n",
            "2065\n",
            "2068\n",
            "2071\n",
            "2074\n",
            "2077\n",
            "2080\n",
            "2083\n",
            "2086\n",
            "2089\n",
            "2092\n",
            "2095\n",
            "2098\n",
            "2101\n",
            "2104\n",
            "2107\n",
            "2110\n",
            "2113\n",
            "2116\n",
            "2119\n",
            "2122\n",
            "2125\n",
            "2128\n",
            "2131\n",
            "2134\n",
            "2137\n",
            "2140\n",
            "2143\n",
            "2146\n",
            "2149\n",
            "2152\n",
            "2155\n",
            "2158\n",
            "2161\n",
            "2164\n",
            "2167\n",
            "2170\n",
            "2173\n",
            "2176\n",
            "2179\n",
            "2182\n",
            "2185\n",
            "2188\n",
            "2191\n",
            "2194\n",
            "2197\n",
            "2200\n",
            "2203\n",
            "2206\n",
            "2209\n",
            "2212\n",
            "2215\n",
            "2218\n",
            "2221\n",
            "2224\n",
            "2227\n",
            "2230\n",
            "2233\n",
            "2236\n",
            "2239\n",
            "2242\n",
            "2245\n",
            "2248\n",
            "2251\n",
            "2254\n",
            "2257\n",
            "2260\n",
            "2263\n",
            "2266\n",
            "2269\n",
            "2272\n",
            "2275\n",
            "2278\n",
            "2281\n",
            "2284\n",
            "2287\n",
            "2290\n",
            "2293\n",
            "2296\n",
            "2299\n",
            "2302\n",
            "2305\n",
            "2308\n",
            "2311\n",
            "2314\n",
            "2317\n",
            "2320\n",
            "2323\n",
            "2326\n",
            "2329\n",
            "2332\n",
            "2335\n",
            "2338\n",
            "2341\n",
            "2344\n",
            "2347\n",
            "2350\n",
            "2353\n",
            "2356\n",
            "2359\n",
            "2362\n",
            "2365\n",
            "2368\n",
            "2371\n",
            "2374\n",
            "2377\n",
            "2380\n",
            "2383\n",
            "2386\n",
            "2389\n",
            "2392\n",
            "2395\n",
            "2398\n",
            "2401\n",
            "2404\n",
            "2407\n",
            "2410\n",
            "2413\n",
            "2416\n",
            "2419\n",
            "2422\n",
            "2425\n",
            "2428\n",
            "2431\n",
            "2434\n",
            "2437\n",
            "2440\n",
            "2443\n",
            "2446\n",
            "2449\n",
            "2452\n",
            "2455\n",
            "2458\n",
            "2461\n",
            "2464\n",
            "2467\n",
            "2470\n",
            "2473\n",
            "2476\n",
            "2479\n",
            "2482\n",
            "2485\n",
            "2488\n",
            "2491\n",
            "2494\n",
            "2497\n",
            "2500\n",
            "2503\n",
            "2506\n",
            "2509\n",
            "2512\n",
            "2515\n",
            "2518\n",
            "2521\n",
            "2524\n",
            "2527\n",
            "2530\n",
            "2533\n",
            "2536\n",
            "2539\n",
            "2542\n",
            "2545\n",
            "2548\n",
            "2551\n",
            "2554\n",
            "2557\n",
            "2560\n",
            "2563\n",
            "2566\n",
            "2569\n",
            "2572\n",
            "2575\n",
            "2578\n",
            "2581\n",
            "2584\n",
            "2587\n",
            "2590\n",
            "2593\n",
            "2596\n",
            "2599\n",
            "2602\n",
            "2605\n",
            "2608\n",
            "2611\n",
            "2614\n",
            "2617\n",
            "2620\n",
            "2623\n",
            "2626\n",
            "2629\n",
            "2632\n",
            "2635\n",
            "2638\n",
            "2641\n",
            "2644\n",
            "2647\n",
            "2650\n",
            "2653\n",
            "2656\n",
            "2659\n",
            "2662\n",
            "2665\n",
            "2668\n",
            "2671\n",
            "2674\n",
            "2677\n",
            "2680\n",
            "2683\n",
            "2686\n",
            "2689\n",
            "2692\n",
            "2695\n",
            "2698\n",
            "2701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7Jq7s6IMNyP",
        "outputId": "5b9faa5d-f682-4f47-abaf-e9db0d3e76da"
      },
      "source": [
        "a,b,c = 0,0,0\r\n",
        "for i in range(0,900):\r\n",
        "  if Ytrain[i] == 1:\r\n",
        "    a+=1\r\n",
        "  elif Ytrain[i] == 2:\r\n",
        "    b+=1\r\n",
        "  elif Ytrain[i] == 3:\r\n",
        "    c+=1\r\n",
        "print(a,b,c)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "236 354 310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DwmTIRYD2Vg"
      },
      "source": [
        "Reshaping data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p0hNEkZD2sv",
        "outputId": "e7d7d218-fe07-46f6-d9bf-6685a7caafef"
      },
      "source": [
        "Xtrain = Xtrain.reshape(Xtrain.shape[0],512,512,1)\n",
        "# Xval = Xval.reshape(Xval.shape[0],512,512,1)\n",
        "#Xtest = Xtest.reshape(Xtest.shape[0],512,512,1)\n",
        "\n",
        "Ytrain = Ytrain-1\n",
        "#Yval = Yval - 1\n",
        "#Ytest = Ytest - 1\n",
        "\n",
        "print(Xtrain.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(900, 512, 512, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8VhLSALD3NR"
      },
      "source": [
        "Importing Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5Tzv14RFfu6"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJkd2KBKzOjr"
      },
      "source": [
        "\n",
        "# # build a sequential model\n",
        "# cnnmodel = tf.keras.Sequential([\n",
        "#       tf.keras.layers.Conv2D(32,(3,3),input_shape=(512,512,1),activation='relu'),\n",
        "#       tf.keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "#       tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "#       tf.keras.layers.MaxPooling2D((2,2)),\n",
        "#       tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "#       tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
        "#       tf.keras.layers.MaxPooling2D((2,2)),\n",
        "#       tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "#       tf.keras.layers.Conv2D(256,(3,3),activation='relu'),\n",
        "#       tf.keras.layers.MaxPooling2D((2,2)),\n",
        "#       tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "#       tf.keras.layers.Conv2D(480,(3,3),activation='relu'),\n",
        "#       tf.keras.layers.MaxPooling2D((2,2)),\n",
        "#       tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "#       tf.keras.layers.Flatten(),\n",
        "#       tf.keras.layers.Dense(1000, activation='relu'),\n",
        "#       tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "#       tf.keras.layers.Dense(100, activation='relu'),\n",
        "# #      tf.keras.layers.Dropout(0.1),\n",
        "\n",
        "#       tf.keras.layers.Dense(3, activation='softmax')\n",
        "\n",
        "# ])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dwua5rcTLGx4"
      },
      "source": [
        "# #0 for meningioma, 1 for glioma, 2 for pituitary tumor\n",
        "# cn = ['meningioma','glioma', 'pituitary']\n",
        "# cnnmodel.summary()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL03GTH97H3a"
      },
      "source": [
        "Shuffling data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvjyYM8uZ9A2"
      },
      "source": [
        "from sklearn.utils import shuffle\r\n",
        "Xtrain, Ytrain = shuffle(Xtrain, Ytrain)\r\n",
        "#Xval, Yval = shuffle(Xval, Yval)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM_Gyq620Alb"
      },
      "source": [
        "# # compile model\n",
        "# cnnmodel.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "# # fit on data for 30 epochs\n",
        "# history = cnnmodel.fit(Xtrain, tf.keras.utils.to_categorical(Ytrain),epochs=25, validation_split=0.33, batch_size=10)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyvgpNj8Pub7",
        "outputId": "2fe5cebc-f7d5-4280-e373-1025b0d40194"
      },
      "source": [
        "tf.keras.utils.to_categorical(Ytrain).shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(900, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHPFBPnfRWtg",
        "outputId": "449c2279-5800-4500-d80c-db47959160a5"
      },
      "source": [
        "np.unique(Ytrain)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fbz3fxbmRlhR"
      },
      "source": [
        "# y_pred = cnnmodel.predict(Xtest)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ekveg1O1WjyR"
      },
      "source": [
        "# prediction = tf.math.argmax(y_pred, axis=1)\n",
        "# equality = tf.math.equal(prediction, Ytest)\n",
        "# accuracy = tf.math.reduce_mean(tf.cast(equality, tf.float32))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGSQVSxqWt2Z"
      },
      "source": [
        "# print(accuracy)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjQ2ZqRyYMQA"
      },
      "source": [
        "# cn[np.argmax(y_pred[140])]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZuRijouYM7-"
      },
      "source": [
        "# # list all data in history\r\n",
        "# print(history.history.keys())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7tHnq-mYCJS"
      },
      "source": [
        "# # summarize history for accuracy\r\n",
        "# plt.plot(history.history['accuracy'])\r\n",
        "# plt.plot(history.history['val_accuracy'])\r\n",
        "# plt.title('model accuracy')\r\n",
        "# plt.ylabel('accuracy')\r\n",
        "# plt.xlabel('epoch')\r\n",
        "# plt.legend(['train', 'test'], loc='upper left')\r\n",
        "# plt.show()\r\n",
        "# # summarize history for loss\r\n",
        "# plt.plot(history.history['loss'])\r\n",
        "# plt.plot(history.history['val_loss'])\r\n",
        "# plt.title('model loss')\r\n",
        "# plt.ylabel('loss')\r\n",
        "# plt.xlabel('epoch')\r\n",
        "# plt.legend(['train', 'test'], loc='upper left')\r\n",
        "# plt.show()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9GVHNG9ir3b"
      },
      "source": [
        "# # retrieve weights from the second hidden layer\r\n",
        "# filters = cnnmodel.layers[0].get_config()\r\n",
        "# print(filters)\r\n",
        "# for i in range(3):\r\n",
        "#   b = cnnmodel.layers[i].count_params()\r\n",
        "#   print(b)\r\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4UC53t5zE59"
      },
      "source": [
        "# layer_names = [layer.name for layer in cnnmodel.layers]\r\n",
        "# layer_names\r\n",
        "\r\n",
        "# layer_outputs = [layer.output for layer in cnnmodel.layers]\r\n",
        "# layer_outputs"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kUxrrJD1UaQ"
      },
      "source": [
        "# #Iterate thru all the layers of the model\r\n",
        "# for layer in cnnmodel.layers:\r\n",
        "#     if 'conv' in layer.name:\r\n",
        "#         weights, bias= layer.get_weights()\r\n",
        "#         print(layer.name)\r\n",
        "        \r\n",
        "#         #normalize filter values between  0 and 1 for visualization\r\n",
        "#         f_min, f_max = weights.min(), weights.max()\r\n",
        "#         filters = (weights - f_min) / (f_max - f_min)  \r\n",
        "#         print(filters.shape[3])\r\n",
        "#         filter_cnt=1\r\n",
        "        \r\n",
        "#         #plotting all the filters\r\n",
        "#         for i in range(filters.shape[3]):\r\n",
        "#             #get the filters\r\n",
        "#             filt=filters[:,:,:, i]\r\n",
        "#             print(filt)\r\n",
        "#             #plotting each of the channel, color image RGB channels\r\n",
        "#             for j in range(filters.shape[0]):\r\n",
        "#                 ax= plt.subplot(filters.shape[3], filters.shape[0], filter_cnt  )\r\n",
        "#                 ax.set_xticks([])\r\n",
        "#                 ax.set_yticks([])\r\n",
        "#                 plt.imshow(filt[:,:, j])\r\n",
        "#                 filter_cnt+=1\r\n",
        "#         plt.show()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1PjuFWwTyY8"
      },
      "source": [
        "## Feature maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBzFb5xQT1iL"
      },
      "source": [
        "# model = tf.keras.models.Model(inputs=cnnmodel.inputs, outputs=cnnmodel.layers[1].output)\r\n",
        "# model.summary()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pWdZJl4Xhp9"
      },
      "source": [
        "# img = np.expand_dims(Xtest[40], axis=0)\r\n",
        "# #Xtest[40].shape\r\n",
        "# feature_maps = model.predict(img)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0Bi7V5ngKog"
      },
      "source": [
        "# # plot all 64 maps in an 8x8 squares\r\n",
        "# square = 8\r\n",
        "# ix = 1\r\n",
        "# for _ in range(square):\r\n",
        "# \tfor _ in range(4):\r\n",
        "# \t\t# specify subplot and turn of axis\r\n",
        "# \t\tax = plt.subplot(square, square, ix)\r\n",
        "# \t\tax.set_xticks([])\r\n",
        "# \t\tax.set_yticks([])\r\n",
        "# \t\t# plot filter channel in grayscale\r\n",
        "# \t\tplt.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\r\n",
        "# \t\tix += 1\r\n",
        "# # show the figure\r\n",
        "# plt.show()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u586MwvUgXoT"
      },
      "source": [
        "# model = tf.keras.models.Model(inputs=cnnmodel.inputs, outputs=cnnmodel.layers[12].output)\r\n",
        "# model.summary()\r\n",
        "# feature_maps = model.predict(img)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mee1zzSn1L-"
      },
      "source": [
        "# # plot all 64 maps in an 8x8 squares\r\n",
        "# square = 8\r\n",
        "# ix = 1\r\n",
        "# for _ in range(square):\r\n",
        "# \tfor _ in range(10):\r\n",
        "# \t\t# specify subplot and turn of axis\r\n",
        "# \t\tax = plt.subplot(square, 10, ix)\r\n",
        "# \t\tax.set_xticks([])\r\n",
        "# \t\tax.set_yticks([])\r\n",
        "# \t\t# plot filter channel in grayscale\r\n",
        "# \t\tplt.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\r\n",
        "# \t\tix += 1\r\n",
        "# # show the figure\r\n",
        "# plt.show()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6vGBDKhrvDc"
      },
      "source": [
        "Plot features of all layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ5DB7p2ryJ-"
      },
      "source": [
        "# def displayfmaps(imagex):\r\n",
        "#   img = np.expand_dims(imagex, axis=0)\r\n",
        "#   for xlayer in cnnmodel.layers:\r\n",
        "#     if 'conv' not in xlayer.name:\r\n",
        "#       continue\r\n",
        "#     model = tf.keras.models.Model(inputs=cnnmodel.inputs, outputs=xlayer.output)\r\n",
        "#     feature_maps = model.predict(img)\r\n",
        "#     square = 8\r\n",
        "#     ix = 1\r\n",
        "#     for _ in range(square):\r\n",
        "#       for _ in range(4):\r\n",
        "#         if(feature_maps[:,:,:].shape > (100,)):\r\n",
        "#           ix +=50\r\n",
        "        \r\n",
        "#       # specify subplot and turn of axis\r\n",
        "#         ax = plt.subplot(square, 10, ix)\r\n",
        "#         ax.set_xticks([])\r\n",
        "#         ax.set_yticks([])\r\n",
        "#         # plot filter channel in grayscale\r\n",
        "#         plt.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\r\n",
        "#         ix += 1\r\n",
        "#   # show the figure\r\n",
        "#     plt.show()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B41wN4vFt203"
      },
      "source": [
        "# displayfmaps(Xtest[1000])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdFtgS4KHfNo"
      },
      "source": [
        "#Xtrain,Ytrain = preprocess_input(Xtrain,Ytrain)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAlbRaumP9ZA",
        "outputId": "cc63369e-eeb5-48d3-d01c-714937157998"
      },
      "source": [
        "print(Xtrain.shape)  # (64, 224, 224)\r\n",
        "Xtrain = np.repeat(Xtrain[...], 3, -1)\r\n",
        "# Xval = np.repeat(Xval[...], 3, -1)\r\n",
        "print(Xtrain.shape)  # (64, 224, 224, 3)\r\n",
        "# print(Xval.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(900, 512, 512, 1)\n",
            "(900, 512, 512, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbcLTB_NKL1T"
      },
      "source": [
        "input_t = tf.keras.Input(shape=(512,512,3))\r\n",
        "res_model = tf.keras.applications.ResNet50(include_top=False,input_tensor=input_t)\r\n",
        " "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch89ViUXLIQs"
      },
      "source": [
        "model = tf.keras.models.Sequential()\r\n",
        "model.add(tf.keras.layers.Lambda(lambda image: tf.image.resize(image, (512, 512)))) \r\n",
        "model.add(res_model)\r\n",
        "model.add(tf.keras.layers.Flatten())\r\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\r\n",
        "model.add(tf.keras.layers.BatchNormalization())\r\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax'))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_vsYzWmsUdY",
        "outputId": "af33becd-9148-4773-deb2-873d1e9efea4"
      },
      "source": [
        "model.build((None,512,512,3))\r\n",
        "print(model.summary())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda (Lambda)              (None, 512, 512, 3)       0         \n",
            "_________________________________________________________________\n",
            "resnet50 (Functional)        (None, 16, 16, 2048)      23587712  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 524288)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               134217984 \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 157,807,491\n",
            "Trainable params: 157,753,859\n",
            "Non-trainable params: 53,632\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1NqM91AtjMS"
      },
      "source": [
        "import os\r\n",
        "# validation_data=(Xval, tf.keras.utils.to_categorical(Yval))\r\n",
        "# np.shape(validation_data)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kz3pEcxa9FS",
        "outputId": "50141e39-af1a-4f44-fa5a-52e6178b0179"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\r\n",
        "                  optimizer=\"rmsprop\",\r\n",
        "                  metrics=['accuracy'])\r\n",
        "checkpoint_path = \"drive/MyDrive/cpoint.ckpt\"\r\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\r\n",
        "\r\n",
        "# Create a callback that saves the model's weights\r\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\r\n",
        "                                                 save_weights_only=True,\r\n",
        "                                                 verbose=1)\r\n",
        "\r\n",
        "# Train the model with the new callback\r\n",
        "\r\n",
        "\r\n",
        "history = model.fit(Xtrain, tf.keras.utils.to_categorical(Ytrain),callbacks=[cp_callback], batch_size=4, epochs=15, verbose=1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "225/225 [==============================] - 55s 171ms/step - loss: 1.4408 - accuracy: 0.5242\n",
            "\n",
            "Epoch 00001: saving model to drive/MyDrive/cpoint.ckpt\n",
            "Epoch 2/15\n",
            "225/225 [==============================] - 39s 174ms/step - loss: 1.1349 - accuracy: 0.5163\n",
            "\n",
            "Epoch 00002: saving model to drive/MyDrive/cpoint.ckpt\n",
            "Epoch 3/15\n",
            "225/225 [==============================] - 39s 175ms/step - loss: 1.1011 - accuracy: 0.5437\n",
            "\n",
            "Epoch 00003: saving model to drive/MyDrive/cpoint.ckpt\n",
            "Epoch 4/15\n",
            "225/225 [==============================] - 39s 174ms/step - loss: 0.8295 - accuracy: 0.6265\n",
            "\n",
            "Epoch 00004: saving model to drive/MyDrive/cpoint.ckpt\n",
            "Epoch 5/15\n",
            "225/225 [==============================] - 39s 175ms/step - loss: 0.7450 - accuracy: 0.6879\n",
            "\n",
            "Epoch 00005: saving model to drive/MyDrive/cpoint.ckpt\n",
            "Epoch 6/15\n",
            "225/225 [==============================] - 39s 173ms/step - loss: 0.6641 - accuracy: 0.7218\n",
            "\n",
            "Epoch 00006: saving model to drive/MyDrive/cpoint.ckpt\n",
            "Epoch 7/15\n",
            "225/225 [==============================] - 39s 174ms/step - loss: 0.7037 - accuracy: 0.7087\n",
            "\n",
            "Epoch 00007: saving model to drive/MyDrive/cpoint.ckpt\n",
            "Epoch 8/15\n",
            "225/225 [==============================] - 39s 174ms/step - loss: 0.5903 - accuracy: 0.7467\n",
            "\n",
            "Epoch 00008: saving model to drive/MyDrive/cpoint.ckpt\n",
            "Epoch 9/15\n",
            "225/225 [==============================] - 39s 173ms/step - loss: 0.6842 - accuracy: 0.7310\n",
            "\n",
            "Epoch 00009: saving model to drive/MyDrive/cpoint.ckpt\n",
            "Epoch 10/15\n",
            "225/225 [==============================] - 39s 174ms/step - loss: 0.5068 - accuracy: 0.8026\n",
            "\n",
            "Epoch 00010: saving model to drive/MyDrive/cpoint.ckpt\n",
            "Epoch 11/15\n",
            "225/225 [==============================] - 39s 173ms/step - loss: 0.5322 - accuracy: 0.8020\n",
            "\n",
            "Epoch 00011: saving model to drive/MyDrive/cpoint.ckpt\n",
            "Epoch 12/15\n",
            "225/225 [==============================] - 39s 173ms/step - loss: 0.4366 - accuracy: 0.8574\n",
            "\n",
            "Epoch 00012: saving model to drive/MyDrive/cpoint.ckpt\n",
            "Epoch 13/15\n",
            "225/225 [==============================] - 39s 173ms/step - loss: 0.4345 - accuracy: 0.8507\n",
            "\n",
            "Epoch 00013: saving model to drive/MyDrive/cpoint.ckpt\n",
            "Epoch 14/15\n",
            "225/225 [==============================] - 39s 173ms/step - loss: 0.4821 - accuracy: 0.8283\n",
            "\n",
            "Epoch 00014: saving model to drive/MyDrive/cpoint.ckpt\n",
            "Epoch 15/15\n",
            "225/225 [==============================] - 39s 173ms/step - loss: 0.3028 - accuracy: 0.8954\n",
            "\n",
            "Epoch 00015: saving model to drive/MyDrive/cpoint.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_PJQaoIsBEt"
      },
      "source": [
        "# model.save(\"my_model.h5\")"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xwUnUDmwQ9Xf",
        "outputId": "e55bdd41-f035-49b9-b7d9-bb695670e336"
      },
      "source": [
        "# model = tf.keras.models.load_model('my_model.h5')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-38-87a591bfcd0a>\", line 1, in <module>\n",
            "    model = tf.keras.models.load_model('my_model.h5')\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\", line 207, in load_model\n",
            "    compile)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\", line 187, in load_model_from_hdf5\n",
            "    load_weights_from_hdf5_group(f['model_weights'], model.layers)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\", line 696, in load_weights_from_hdf5_group\n",
            "    weight_values = [np.asarray(g[weight_name]) for weight_name in weight_names]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\", line 696, in <listcomp>\n",
            "    weight_values = [np.asarray(g[weight_name]) for weight_name in weight_names]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\", line 83, in asarray\n",
            "    return array(a, dtype, copy=False, order=order)\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/h5py/_hl/dataset.py\", line 772, in __array__\n",
            "    self.read_direct(arr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/h5py/_hl/dataset.py\", line 733, in read_direct\n",
            "    self.id.read(mspace, fspace, dest, dxpl=self._dxpl)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 739, in getmodule\n",
            "    f = getabsfile(module)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 708, in getabsfile\n",
            "    _filename = getsourcefile(object) or getfile(object)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
            "    if os.path.exists(filename):\n",
            "  File \"/usr/lib/python3.6/genericpath.py\", line 19, in exists\n",
            "    os.stat(path)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2TJRPxfjpjz"
      },
      "source": [
        "# import os\r\n",
        "# checkpoint_path = \"drive/MyDrive/cp.h5\"\r\n",
        "# checkpoint_dir = os.path.dirname(checkpoint_path)\r\n",
        "# model.save(checkpoint_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M94Ax45akIxf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}